# Fluent Bit Configuration for Log Aggregation
# Korean Digital Textbook Platform

[SERVICE]
    Flush        5
    Daemon       Off
    Log_Level    info
    Parsers_File parsers.conf
    Plugins_File plugins.conf
    HTTP_Server  On
    HTTP_Listen  0.0.0.0
    HTTP_Port    2020
    Health_Check On

# Input: Frontend Application Logs
[INPUT]
    Name              tail
    Path              /var/log/digitalbook/frontend/*.log
    Parser            json
    Tag               frontend.*
    Refresh_Interval  5
    Skip_Long_Lines   On
    DB                /var/log/fluentbit-frontend.db
    Mem_Buf_Limit     5MB

# Input: Backend API Logs
[INPUT]
    Name              tail
    Path              /var/log/digitalbook/backend/*.log
    Parser            json
    Tag               backend.*
    Refresh_Interval  5
    Skip_Long_Lines   On
    DB                /var/log/fluentbit-backend.db
    Mem_Buf_Limit     5MB

# Input: Nginx Access Logs
[INPUT]
    Name              tail
    Path              /var/log/nginx/access.log
    Parser            nginx
    Tag               nginx.access
    Refresh_Interval  5
    Skip_Long_Lines   On
    DB                /var/log/fluentbit-nginx-access.db
    Mem_Buf_Limit     5MB

# Input: Nginx Error Logs
[INPUT]
    Name              tail
    Path              /var/log/nginx/error.log
    Parser            nginx_error
    Tag               nginx.error
    Refresh_Interval  5
    Skip_Long_Lines   On
    DB                /var/log/fluentbit-nginx-error.db
    Mem_Buf_Limit     5MB

# Input: PostgreSQL Logs
[INPUT]
    Name              tail
    Path              /var/log/postgresql/*.log
    Parser            postgresql
    Tag               database.postgresql
    Refresh_Interval  5
    Skip_Long_Lines   On
    DB                /var/log/fluentbit-postgresql.db
    Mem_Buf_Limit     5MB

# Input: System Logs
[INPUT]
    Name              systemd
    Tag               system.*
    Read_From_Tail    On
    Strip_Underscores On

# Filter: Add metadata to all logs
[FILTER]
    Name              record_modifier
    Match             *
    Record            hostname ${HOSTNAME}
    Record            environment production
    Record            platform digitalbook

# Filter: Parse and enrich frontend logs
[FILTER]
    Name              parser
    Match             frontend.*
    Key_Name          log
    Parser            frontend_parser
    Reserve_Data      On

# Filter: Parse and enrich backend logs
[FILTER]
    Name              parser
    Match             backend.*
    Key_Name          log
    Parser            backend_parser
    Reserve_Data      On

# Filter: Add GeoIP data to nginx logs
[FILTER]
    Name              geoip2
    Match             nginx.access
    Database          /usr/share/GeoIP/GeoLite2-City.mmdb
    Lookup_key        remote_addr
    Record            country remote_addr %{country.names.en}
    Record            city remote_addr %{city.names.en}
    Record            latitude remote_addr %{location.latitude}
    Record            longitude remote_addr %{location.longitude}

# Filter: Detect security events
[FILTER]
    Name              lua
    Match             nginx.access
    Script            security_detection.lua
    Call              detect_security_events

# Filter: Calculate response time percentiles
[FILTER]
    Name              lua
    Match             backend.*
    Script            response_time.lua
    Call              calculate_percentiles

# Output: Elasticsearch for long-term storage and analysis
[OUTPUT]
    Name              es
    Match             *
    Host              localhost
    Port              9200
    Index             digitalbook
    Type              _doc
    Time_Key          @timestamp
    Include_Tag_Key   On
    Tag_Key           tag
    Buffer_Size       4KB
    Retry_Limit       5

# Output: Loki for Grafana integration
[OUTPUT]
    Name              loki
    Match             *
    Host              localhost
    Port              3100
    Labels            job=digitalbook, env=production
    Line_Format       json
    Remove_Keys       stream

# Output: S3 for backup and compliance
[OUTPUT]
    Name              s3
    Match             *
    Region            ap-northeast-2
    Bucket            digitalbook-logs
    Total_file_size   50M
    Use_put_object    On
    Upload_timeout    10s
    Store_dir         /tmp/fluent-bit/s3

# Output: Alert on critical errors
[OUTPUT]
    Name              http
    Match             *.error
    Host              localhost
    Port              8080
    URI               /alerts
    Format            json
    Header            Content-Type application/json
    Header            Authorization Bearer ${ALERT_TOKEN}